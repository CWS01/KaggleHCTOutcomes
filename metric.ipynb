{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nTo evaluate the equitable prediction of transplant survival outcomes,\nwe use the concordance index (C-index) between a series of event\ntimes and a predicted score across each race group.\n \nIt represents the global assessment of the model discrimination power:\nthis is the modelâ€™s ability to correctly provide a reliable ranking\nof the survival times based on the individual risk scores.\n \nThe concordance index is a value between 0 and 1 where:\n \n0.5 is the expected result from random predictions,\n1.0 is perfect concordance (with no censoring, otherwise <1.0),\n0.0 is perfect anti-concordance (with no censoring, otherwise >0.0)\n\n\"\"\"\n\nimport pandas as pd\nimport pandas.api.types\nimport numpy as np\nfrom lifelines.utils import concordance_index\n\nclass ParticipantVisibleError(Exception):\n    pass\n\n\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n    \"\"\"\n    >>> import pandas as pd\n    >>> row_id_column_name = \"id\"\n    >>> y_pred = {'prediction': {0: 1.0, 1: 0.0, 2: 1.0}}\n    >>> y_pred = pd.DataFrame(y_pred)\n    >>> y_pred.insert(0, row_id_column_name, range(len(y_pred)))\n    >>> y_true = { 'efs': {0: 1.0, 1: 0.0, 2: 0.0}, 'efs_time': {0: 25.1234,1: 250.1234,2: 2500.1234}, 'race_group': {0: 'race_group_1', 1: 'race_group_1', 2: 'race_group_1'}}\n    >>> y_true = pd.DataFrame(y_true)\n    >>> y_true.insert(0, row_id_column_name, range(len(y_true)))\n    >>> score(y_true.copy(), y_pred.copy(), row_id_column_name)\n    0.75\n    \"\"\"\n    \n    del solution[row_id_column_name]\n    del submission[row_id_column_name]\n    \n    event_label = 'efs'\n    interval_label = 'efs_time'\n    prediction_label = 'prediction'\n    for col in submission.columns:\n        if not pandas.api.types.is_numeric_dtype(submission[col]):\n            raise ParticipantVisibleError(f'Submission column {col} must be a number')\n    # Merging solution and submission dfs on ID\n    merged_df = pd.concat([solution, submission], axis=1)\n    merged_df.reset_index(inplace=True)\n    merged_df_race_dict = dict(merged_df.groupby(['race_group']).groups)\n    metric_list = []\n    for race in merged_df_race_dict.keys():\n        # Retrieving values from y_test based on index\n        indices = sorted(merged_df_race_dict[race])\n        merged_df_race = merged_df.iloc[indices]\n        # Calculate the concordance index\n        c_index_race = concordance_index(\n                        merged_df_race[interval_label],\n                        -merged_df_race[prediction_label],\n                        merged_df_race[event_label])\n        metric_list.append(c_index_race)\n    return float(np.mean(metric_list)-np.sqrt(np.var(metric_list)))\n","metadata":{"_uuid":"2a1239f3-55fc-4dbb-9d3a-e90bfffa038c","_cell_guid":"4cf02a6f-b7e9-4360-892d-b1a50793eb12","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"execution_count":null}]}